import os
import json
import psycopg2
from datetime import date, datetime
from dotenv import load_dotenv
from openai import OpenAI

# Load .env
load_dotenv("../api/OSINT.env")
client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

# Connect to DB
def connect_db():
    return psycopg2.connect(
        dbname=os.getenv("DB_NAME"),
        user=os.getenv("DB_USER"),
        password=os.getenv("DB_PASSWORD"),
        host=os.getenv("DB_HOST"),
        port=os.getenv("DB_PORT")
    )

# Fetch or insert asset
def get_or_create_asset_id(asset_name):
    conn = connect_db()
    cur = conn.cursor()
    cur.execute("SELECT id FROM assets WHERE name = %s", (asset_name,))
    result = cur.fetchone()
    if result:
        cur.close(); conn.close()
        return result[0]

    cur.execute("""
        INSERT INTO assets (name, asset_type, owner, description, criticality, location, created_at, updated_at)
        VALUES (%s, %s, %s, %s, %s, %s, NOW(), NOW()) RETURNING id
    """, (asset_name, "Uncategorized", "Unknown", "Auto-added from risk_analysis.py", "Medium", "N/A"))
    asset_id = cur.fetchone()[0]
    conn.commit()
    cur.close(); conn.close()
    return asset_id

# Fetch or insert threat
def get_or_create_threat_id(threat_name):
    conn = connect_db()
    cur = conn.cursor()
    cur.execute("SELECT id FROM threats WHERE name = %s", (threat_name,))
    result = cur.fetchone()
    if result:
        cur.close(); conn.close()
        return result[0]

    cur.execute("""
        INSERT INTO threats (name, threat_type, source, description, tactics, techniques, indicators, created_at, updated_at)
        VALUES (%s, %s, %s, %s, %s, %s, %s, NOW(), NOW()) RETURNING id
    """, (threat_name, "Unknown", "Generated by AI", "Auto-generated threat for scoring.", "N/A", "N/A", "N/A"))
    threat_id = cur.fetchone()[0]
    conn.commit()
    cur.close(); conn.close()
    return threat_id

# Analyze risk using GPT
def analyze_risk(threat_name):
    prompt = f"""Given the threat '{threat_name}', assign a Likelihood (1-5) and Impact (1-5) score based on cybersecurity standards. 
Respond ONLY in this JSON format:
{{"likelihood": 4, "impact": 5, "explanation": "Short explanation"}}

Keep explanation concise."""
    try:
        response = client.chat.completions.create(
            model="gpt-4o",
            messages=[
                {"role": "system", "content": "You are a cybersecurity assistant scoring threats."},
                {"role": "user", "content": prompt}
            ]
        )
        message = response.choices[0].message.content.strip()
        if message.startswith("```json"):
            message = message.replace("```json", "").replace("```", "").strip()
        return json.loads(message)
    except Exception as e:
        return {"likelihood": 3, "impact": 3, "explanation": f"Fallback: GPT error: {str(e)}"}

# Insert into risk_assessments
def insert_risk_score(asset_id, threat_id, likelihood, impact, risk_score, explanation):
    conn = connect_db()
    cur = conn.cursor()
    cur.execute("""
        INSERT INTO risk_assessments (
            asset_id, threat_id, likelihood, impact, risk_score, risk_level,
            assessment_date, created_at, updated_at, notes
        )
        VALUES (%s, %s, %s, %s, %s, %s, %s, NOW(), NOW(), %s)
    """, (
        asset_id, threat_id, likelihood, impact, risk_score,
        "High" if risk_score > 20 else "Medium", date.today(), explanation
    ))
    conn.commit()
    cur.close(); conn.close()
    print("✅ Risk score inserted into database.")

# Main execution
if __name__ == "__main__":
    threat = input("Enter threat name (e.g., SQL Injection): ").strip()
    asset = input("Enter asset name (e.g., Servers): ").strip()

    print("⚙️  Fetching IDs and generating risk score...")
    asset_id = get_or_create_asset_id(asset)
    threat_id = get_or_create_threat_id(threat)

    risk_result = analyze_risk(threat)
    likelihood = risk_result.get("likelihood", 3)
    impact = risk_result.get("impact", 3)
    explanation = risk_result.get("explanation", "No explanation returned.")

    risk_score = likelihood * impact
    insert_risk_score(asset_id, threat_id, likelihood, impact, risk_score, explanation)
